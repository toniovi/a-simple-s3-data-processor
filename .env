#===============================================================================
# Make sure to update these variables manually on creating a new project !
# (Github/Local) Secrets to .env Variables, and Other Variables that must be updated manually
#===============================================================================

# ------------------------------------------------------------------------------
# Project/Application/Artifact/... name
# ------------------------------------------------------------------------------

CLIENT_NAME=acme
PROJECT_NAME=a-simple-s3-data-processor

PROJECT_ROOT=/workspaces/${PROJECT_NAME}
PROJECT_GIT_REPO_URL=git@github.com:toniovi/${PROJECT_NAME}.git

PROJECT_DOCKER_CONTAINER_IMAGE=python:3.11-bookworm


#===============================================================================
# Google Cloud Platform
#===============================================================================

GCLOUD_PROJECT=acme-data
GCLOUD_PROJECT_REGION=europe-west9
GCLOUD_LOCATION=europe

GCLOUD_ARTIFACT_REGION=europe-docker.pkg.dev
GCLOUD_ARTIFACT_REGISTRY=acme-artifacts

GCLOUD_BIGQUERY_DBT_DATASET_NAME=acme-artifacts

# ------------------------------------------------------------------------------
# Service Accounts Keys' created for the Project's Automatisation
# ------------------------------------------------------------------------------

GCLOUD_SERVICE_ACCOUNT=acme@acme-data.iam.gserviceaccount.com

GCLOUD_DEPLOYMENT_SERVICE_ACCOUNT=${GCLOUD_SERVICE_ACCOUNT}
GCP_SERVICE_ACCOUNT_NAME=${GCLOUD_SERVICE_ACCOUNT}

DBT_ENV_SECRET_GCP_SERVICE_ACCOUNT_KEY_JSON=${DBT_ENV_SECRET_ACME_GCP_SERVICE_ACCOUNT_KEY_JSON}

# ------------------------------------------------------------------------------
# Cloud Run
# ------------------------------------------------------------------------------

#You need to create it manually the first time, then fill it here
CLOUD_RUN_SERVICE_URL=''

CLOUD_RUN_INVOKER_ACCOUNT=${GCLOUD_SERVICE_ACCOUNT}

# ------------------------------------------------------------------------------
# Cloud Storage variables
# ------------------------------------------------------------------------------

CLOUD_STORAGE_BUCKET=acme-data-bucket

# ------------------------------------------------------------------------------
# Google Cloud Email File Transfer App
# ------------------------------------------------------------------------------

FILE_TRANSFER_APP_GMAIL_USERNAME="antonio.at.acme.data@gmail.com"
FILE_TRANSFER_APP_GOOGLE_ACCOUNT_APP_PASSWORD=${ANTONIO_ACME_GCP_EMAIL_FILE_TRANSFER_APP_PASSWORD}


#===============================================================================
# Azure
#===============================================================================

AZURE_RESSOURCE_GROUP=acme-modern-data-platform

# ------------------------------------------------------------------------------
# Azure Storage variables
# ------------------------------------------------------------------------------

DBT_ENV_SECRET_AZURE_STORAGE_CONN_STRING=${ACME_AZURE_STORAGE_ACCOUNT_ACMEDATALAKE_CONN_STRING}

DBT_ENV_SECRET_AZURE_STORAGE_SAS_TOKEN_SILVER=${ACME_AZURE_STORAGE_ACCOUNT_ACMEDATALAKE_SILVER_SAS_TOKEN}
DBT_ENV_SECRET_AZURE_STORAGE_SAS_TOKEN_BRONZE=${ACME_AZURE_STORAGE_ACCOUNT_ACMEDATALAKE_BRONZE_SAS_TOKEN}

AZURE_DATA_LAKE_STORAGE_ACCOUNT=$(python -c 'import os; from urllib.parse import urlparse; conn_string = os.getenv("DBT_ENV_SECRET_AZURE_STORAGE_CONN_STRING"); print(urlparse("?" + conn_string.replace(";", "&")).query.split("AccountName=")[1].split("&")[0] if conn_string else "");')
AZURE_DATA_LAKE_STORAGE_ACCOUNT_KEY=$(python -c 'import os; from urllib.parse import urlparse; conn_string = os.getenv("DBT_ENV_SECRET_AZURE_STORAGE_CONN_STRING"); print(urlparse("?" + conn_string.replace(";", "&")).query.split("AccountKey=")[1].split("&")[0] if conn_string else "");')

# ------------------------------------------------------------------------------
# Azure Databricks variables
# ------------------------------------------------------------------------------

DBT_ENV_SECRET_DATABRICKS_SQL_WAREHOUSE_TOKEN=${DBT_ENV_SECRET_ACME_AZURE_SMALLEST_WAREHOUSE_TOKEN}

DATABRICKS_SQL_WAREHOUSE_TOKEN_HOST=adb-756XXXXXXXXXXX8.8.azuredatabricks.net
DATABRICKS_SQL_WAREHOUSE_TOKEN_HTTP_PATH=/sql/1.0/warehouses/5XXXXXXXXXXXXXe


# The following is for the Databricks CLI & the Databrikcs VS Code extension, which will look for the following variables automatically (prefixed 'DATABRICKS_')
DATABRICKS_TOKEN=${DBT_ENV_SECRET_DATABRICKS_SQL_WAREHOUSE_TOKEN}
DATABRICKS_HOST=${DATABRICKS_SQL_WAREHOUSE_TOKEN_HOST}
DATABRICKS_HTTP_PATH=${DATABRICKS_SQL_WAREHOUSE_TOKEN_HTTP_PATH}

# You'll need to fill this variable wtth the cluster ID of the cluster you've created
DATABRICKS_CLUSTER_ID=''


# ------------------------------------------------------------------------------
# Other Azure variables
# ------------------------------------------------------------------------------

AZURE_CONTAINER_PUSH_TOKEN_NAME=''
AZURE_CONTAINER_REGISTRY=''
AZURE_CONTAINER_APP_ENV=''


# ------------------------------------------------------------------------------
# dbt
# ------------------------------------------------------------------------------

DBT_PROJECT_NAME_GOLD=dbt_dashboards
DBT_PROJECT_DIR_GOLD=${PROJECT_ROOT}/${DBT_PROJECT_NAME_GOLD}

# ------------------------------------------------------------------------------
# Local Postgres
# ------------------------------------------------------------------------------

POSTGRES_DATABASE_NAME=postgres_database
POSTGRES_RAW_DATA_SCHEMA=gold
POSTGRES_USER=postgres_user
POSTGRES_PASSWORD=postgrespwd123



# ------------------------------------------------------------------------------
# Lightdash
# ------------------------------------------------------------------------------

LIGHTDASH_SECRET=lightdash_secret_123


# ------------------------------------------------------------------------------
# Dagster
# ------------------------------------------------------------------------------

DAGSTER_PROJECT_FOLDER_NAME=dagster_orchestration
DAGSTER_HOME=${PROJECT_ROOT}

DAGSTER_CLOUD_API_TOKEN=${ACME_DAGSTER_CLOUD_API_AGENT_TOKEN}

DAGSTER_CLOUD_ORGANIZATION=acme-data
DAGSTER_CLOUD_DEPLOYMENT=prod


# ------------------------------------------------------------------------------
# Sling
# ------------------------------------------------------------------------------

SLING_HOME_DIR=${PROJECT_ROOT}/.sling


# ------------------------------------------------------------------------------
# Superset
# ------------------------------------------------------------------------------

SUPERSET_ADMIN=admin
SUPERSET_PASSWORD=admin


# ------------------------------------------------------------------------------
# Data gouv fr
# ------------------------------------------------------------------------------

DATA_GOUV_FR_API_KEY=${ACME_DATA_GOUV_FR_API_KEY}


# ------------------------------------------------------------------------------
# External Datalakes
# ------------------------------------------------------------------------------

EXTERNAL_AZURE_DATA_LAKE_STORAGE_ACCOUNT='acmeexternaldatalake'

DBT_ENV_SECRET_EXTERNAL_AZURE_STORAGE_SAS_TOKEN_URL_BRONZE=${ACME_AZUREDATALAKE_BRONZE_SAS_TOKEN_URL}
DBT_ENV_SECRET_EXTERNAL_AZURE_STORAGE_SAS_TOKEN_URL_SILVER=${ACME_AZUREDATALAKE_SILVER_SAS_TOKEN_URL}



#===============================================================================
# GENERAL UTILITIES â€” Split env Variables to be able to use in dbt config
#===============================================================================

DBT_ENV_SECRET_SERV_ACC_KEY_TYPE=$(python -c 'import json,os;key_json=os.getenv("DBT_ENV_SECRET_GCP_SERVICE_ACCOUNT_KEY_JSON");print(json.loads(key_json)["type"] if key_json else "")')
DBT_ENV_SECRET_SERV_ACC_KEY_PROJECT_ID=$(python -c 'import json,os;key_json=os.getenv("DBT_ENV_SECRET_GCP_SERVICE_ACCOUNT_KEY_JSON");print(json.loads(key_json)["project_id"] if key_json else "")')
DBT_ENV_SECRET_SERV_ACC_KEY_PRIVATE_KEY_ID=$(python -c 'import json,os;key_json=os.getenv("DBT_ENV_SECRET_GCP_SERVICE_ACCOUNT_KEY_JSON");print(json.loads(key_json)["private_key_id"] if key_json else "")')
DBT_ENV_SECRET_SERV_ACC_KEY_PRIVATE_KEY=$(python -c 'import json,os;key_json=os.getenv("DBT_ENV_SECRET_GCP_SERVICE_ACCOUNT_KEY_JSON");print(json.loads(key_json)["private_key"] if key_json else "")')
DBT_ENV_SECRET_SERV_ACC_KEY_CLIENT_EMAIL=$(python -c 'import json,os;key_json=os.getenv("DBT_ENV_SECRET_GCP_SERVICE_ACCOUNT_KEY_JSON");print(json.loads(key_json)["client_email"] if key_json else "")')
DBT_ENV_SECRET_SERV_ACC_KEY_CLIENT_ID=$(python -c 'import json,os;key_json=os.getenv("DBT_ENV_SECRET_GCP_SERVICE_ACCOUNT_KEY_JSON");print(json.loads(key_json)["client_id"] if key_json else "")')
DBT_ENV_SECRET_SERV_ACC_KEY_AUTH_URI=$(python -c 'import json,os;key_json=os.getenv("DBT_ENV_SECRET_GCP_SERVICE_ACCOUNT_KEY_JSON");print(json.loads(key_json)["auth_uri"] if key_json else "")')
DBT_ENV_SECRET_SERV_ACC_KEY_TOKEN_URI=$(python -c 'import json,os;key_json=os.getenv("DBT_ENV_SECRET_GCP_SERVICE_ACCOUNT_KEY_JSON");print(json.loads(key_json)["token_uri"] if key_json else "")')
DBT_ENV_SECRET_SERV_ACC_KEY_AUTH_PROVIDER_X509_CERT_URL=$(python -c 'import json,os;key_json=os.getenv("DBT_ENV_SECRET_GCP_SERVICE_ACCOUNT_KEY_JSON");print(json.loads(key_json)["auth_provider_x509_cert_url"] if key_json else "")')
DBT_ENV_SECRET_SERV_ACC_KEY_CLIENT_X509_CERT_URL=$(python -c 'import json,os;key_json=os.getenv("DBT_ENV_SECRET_GCP_SERVICE_ACCOUNT_KEY_JSON");print(json.loads(key_json)["client_x509_cert_url"] if key_json else "")')

